# Poforlio
Codes for machine learning algorithms, data technology project, prescriptive modeling &amp; optimization projects, A/B test that I did:

# Machine Learning Algorithms
# Linear Regression: Ordinary Least Squares, Gerneralized Least Squares, Penalized Least Squares (LASSO, Ridge)
### [Telecom Work Measurement Study -OLS](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/Telecom_Work_Measurement_Study.R)
This model is some telecom data and evaluates different linear regression models that determines the relationship between the dependent variable of number of hours worked, and some independent variables.

### [Claims_Study.R](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/LASSO/Claims_Study.R)
This dataset includes insurance claims severities from Allstate. In this task, first we modify the dataset to show the claims which are higher than $100 and ran an OLS regression model. Next, we found the least mean-squared-error with LASSO model. Then, the best lambda was found with cross validation. 

### [LASSO Model](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/LASSO/03.R)
The codes for LASSO Model

### [Naive Bayes Classifier](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/Module4_Tutorial_GAMClassifcation_with.pdf)
Credit card assesement case: sample for application of Naive Bayes Classifier with python code

# Logistic  Regression
### [Caravan_Insurance_Study](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/Logistic%20Regression/Caravan_Insurance_Study.R)
I was given a dataset that indicates whether owners purchased caravan insurance or not in this database. This dataset also includes some demographic information about the owners. This study runs a logistic regression in order to see how these characteristics relate to the insurance buying decision of the caravan owners.

# Support Vector Machines(SVM)

# Classification Trees
### [Wine Data Study - Classification Tree Model](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/SVM%20Classification%20Tree/Wine_Data_Classification.R)
This study looks at a Wine Data dataset that includes some features about the quality and characteristics of a variety of wines. The outcome variable is the quality of wines. This model aims to use a classification tree to find the most relevant set of features that can predict the wine quality the best.

# Random Forest, Graident Boosting and Neural Network
### [Wine Data Study - Random Forest, Gradient Boosting, and Neural Networks](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/Neural%20Network/Wine_Data-trees_and_nnets.R)
In the previous study, we used classification ree to find the features that can prodict the wine quality best. And in this assignment we will set up a random forest model and then a gradient boosting model. Later on, we build up neural networks, compare single layer model and a model with hidden layers.

# Clustering
### [Wine Data Study - Clustering](https://github.com/qli447/Poforlio/blob/main/Machine%20Learning/Clustering%20PCA/Wine%20Data%20Study%20-%20Clustering.R)
We still use the same dataset of wine qualities, and in this study we run a clustering analysis to find out about any clusters in the set that might be useful for explaining data.

# PCA

# Data Technology

### [Twitter Trending Scores System Milestone1 Server](https://github.com/qli447/TwitterTrendingScoreSystem/blob/main/server.py)

### [Twitter Trending Scores System Milestone2 Calculation](https://github.com/qli447/TwitterTrendingScoreSystemCalculationV1.0)

In this project, my group and I build a system to continuously score phrases and words based on their “trendiness” on Twitter. The project was developed on a Linux (Ubuntu 20.04) Virtual Machine. In the first part of this project(Milestone1), we need to read tweets from the Twitter API or a file and write them to a file on disk. For Milestone2, we create a data warehouse for the tweets from Twitter and then calculate the trending scores. In addition, to complete the calcualtion, we have a “Trendiness Score” formula, and the trendiness of a phrase p at time t is computed as follows: Trendiness(p, t) = log10[ Prob(p|current minute at t) ] - log10[ Prob(p|minute prior to t) ]

# Prescriptive modeling &amp; optimization projects:

•Allocation, Blending, Covering 

•Markdown Pricing 

•Financial Portfolio 

•Min Cost Flow, Max Flow, Shortest Path 

•Transportation 

•Capital Budgeting/Knapsack 

•Demerger 

•Production Planning 

•Staff Scheduling 

•Service Center Location 

•DC Location + Transportation 

•Traveling Salesman 

•Set Covering, Set Packing, Set Partitioning 

•Subscription Box Management 

•Vehicle Routing 

•Job Shop Scheduling 

•Performance Analysis using DEA
